-------------------------------- 2023-05-09 --------------------------------

Los datos fueron modificados: 
  * FWI es constante entre incendios (vuela de los paisajes y de los parámetros)
  * elevation va estandarizada, y se tiene que estandarizar la distance para 
    calcular la slope
  * la vegetación es una integer matrix, codificando de 0 a k, con 
    99 == non-burnable
  
  * incluir en los datos los 2 dry forests y la estepa. La reclasificación
    se dará al asignar los mismos parámetros, por ejemplo, a shrubland y steppe.


Editar código de prior predictive checks para que use los nuevos datos.
# DONE, pero queda editar la parte en que explora las similarities.

Editar similarity metric selection.R

Hacer funciones para flexibilizar los códigos de vegetación.
En muchos paisajes va a haber pocos vegetation types. Algunos estarán ausentes
y otros serán tan poco abundantes que será sensato directamente asumirlos
ausentes (pensar bien el criterio en base a su abundancia absoluta o relativa**).
En ambos casos, la forma de "ignorarlos" es hacer que su intercept sea igual
al de otra vegetation type. Entonces, necesitamos recodificar todas las veg
types funcionalmente ausentes.

Lo ideal sería indicar qué tipos de vegetación vas a considerar/usar, y que 
en base a eso sepa cómo sinonimizar los demás. 
Entonces, si voy a usar 
  shrubland, dry_b
la función debería convertir los demás parámetros de veg a estas clases, 
siguiendo un orden de preferencia como la siguiente (chequear mirando análisis 
de patrones):

  shrubland: dry_b, steppe, dry_a, wet, subalpine;
  subalpine: wet, dry_a, dry_b, shrubland, steppe;
  wet:       subalpine, dry_a, dry_b, shrubland, steppe;
  dry_a:     subalpine, wet, dry_b, shrubland, steppe;
  dry_b:     shrubland, dry_a, wet, subalpine, steppe;
  steppe:    shrubland, dry_b, dry_a, wet, subalpine;

Ejemplo:
si en un paisaje tengo solo
  dry_a, 
  steppe, 
debería hacer estas conversiones:
  subalpine: dry_a,
  wet:       dry_a, 
  dry_b:     dry_a
  shrubland: steppe

El vector de intercepts, cuyo orden es
{shrubland, subalpine, wet, dry_a, dry_b, steppe}
quedaría
{steppe, dry_a, dry_a, dry_a, dry_a, steppe}

** Criterio de escasez para ignorar veg types:
- Area menor al 1% del paisaje quemable efectivo (es decir, descontando
  islas de quemable no conectadas con el punto de ignición) 
  OR
- Área < 100 píxeles.

Problemas de criterios areales: a veces un área muy pequeña puede tener 
efectos importantes. 
Ejemplo: el fuego empieza en un parchecito de subalpine, donde hay baja flamm.
Se hace muy peque hasta extinguirse sin llegar al matorral. En cambio, 
si empieza en matorral, aunque sea pequeño el parche, logra quemar un 
número de píxeles suficientemente grande como para quemar el subalpine que 
rodea al matorral.
Si creemos que las condiciones iniciales son muy importantes, entonces esto 
también debería definirse según la distancia al punto de ignición.
  
Antes de complicarme con esto, mejor evaluar bien cuántos veg_types hay por 
paisaje y su abundancia relativa. Quizás es muy evidente si hace falta quitar 
clases o no, y hasta podría hacerse a ojo.




---- TAREAS PARA MÁS LUEGO

- Elegir la métrica de similitud 
- Volver a descargar todos los paisajes con las clases de vegetación completas
  (dry forests separados), y hacer paisajes para R con las 6 clases (incluye
  estepa).
- Editar códigos de waves para que "ignore" los veg types ausentes o escasos.
- Analizar en GEE la abundancia de cada veg type (6) en paisajes y en incendios,
  para todos los fuegos (ig point known y unknown)
  
  
  
  
---- CONSIDERACIONES RANDOM EFFECTS --------------------------------- 
  
En vez de ajustar un modelo de loglik para cada fuego, quizás convenga
modificar a mano los intercepts y el sd de los random effects para 
que se ajuste bien a todos los incendios, asumiendo que la likelihood de los
demás parámetros casi no va a cambiar, ya que son incendios pequeños
que informan poco. 

Se pueden ajustar modelos de tipo 
raneff ~ fire size, 
(usando todas las muestras de la posterior de incendios con ig conocido)

luego predecir estocásticamente el raneff de los fuegos no usados
y evaluar qué media y sd ajusta bien a todo el set de incendios completo. 

A posteriori, podemos usar la relación entre fire size e intercept para
estimar el punto de ignición, muestreando intercepts de ese modelo.  
 
En fin, quizás no sea necesario ajustar los 210 MVN models, sino 51.


----
Otra: si los MVN son muy lentos como para ajustar a 210 datos, podemos
usar GPs y poner dos umbrales para la parte de rechazo de partículas:
1) el e_j propuesto tiene que superar el umbral del borde del terreno;
2) si pasa ese filtro, e_j tiene que ser mayor a un umbral deseado.

El primer filtro evita evaluar el GP cuando el GP queda out of bounds. 
Esto requeriría guardar un GP (likelihood) y un GAM (in_bounds_model) 
por incendio, pero no me parece mal. 

Estudiar cómo sería un gibbs sampler para un modelo como el mío.


___ USAR GIBBS!!!

Yo me preocupaba por que la likelihood estuviera truncada de abajo, 
pero una forma muy simple de resolver eso es usar el GP completo y 
rechazar las partículas que tienen una like < lower_limit + delta

Supongamos que lower_limit = 0.05 es el overlap del incendio más grande.
delta podría ser algo así como 2Sigma del GP cuando está fuera de bounds.

Para asegurarnos de nunca estar cerca de ese borde, al momento de 
samplear random intercepts, hacemos lo siguiente:

01) proponemos un alpha_star de la distrib de propuestas
02) sorteamos si está in_bounds con el in_bounds_gam
03) evaluamos su like con el GP, = like(alpha_star)
		(en este paso, simulamos con el GP, para considerar la 
		 uncertainty del metamodelo)
04) la conservamos si like(alpha_star) > lower_limit + delta
05) alpha_i = sorteo(alpha_star, alpha_i-1) tipo metropolis.

Otra forma más simple sería sin usar el in_bounds_gam, 
simplemente rechazando todo lo que esté < lower_limit + delta.
Pero seguramente usar el gam disminuiría la tasa de rechazo.

Este artilugio sería como un truncamiento de la likelihood function 
en la dimensión del intercept. Como no podemos ver cuánto le erramos 
a la verdadera similarity porque el paisaje nos restringe, sabemos
que es baja y la igualamos a cero. Esto afectaría principalmente 
a la incertidumbre sobre cada intercept, y no tanto a la incertidumbre
sobre los hiperparametros.

Para el punto de ignición podemos hacer exactamente lo mismo, y estimarlo
de forma discreta. luego, agregamos un filtro similar al que tenemos
para el intercept:
	nos fijamos si el pixel propuesto está en el incendio
	si está, seguimos, evaluando la likelihood y todo; si no, 
	probamos con otro.



---- NOTAS LOGLIK PARA CADA INCENDIO -------------------------------------
2023-10-10


Intenté ajustar un MVN para un incendio y fue un terrible fracaso. 
También fracasó usar un GP para un incendio, y me pasé a un fixed effects model
porque la RAE apuraba. 

A posteriori vi que la superficie de similitud es mucho más informativa si la miramos 
en la escala de la similitud, no log ni logit. Y más aún si trabajamos con fuegos
separados, ya que la similitud está en [~0, 1].

Por otro lado, tenía bugs en el código de las olas, haciendo que el aprendizaje 
no fuera muy acumulativo. En momentos el GP se ponía puntudo y traía problemas.
Ahí hay que ajustarlo con más datos y ya. 
Y nunca hay que quitar los out_of_bounds data para ajustar el GP. Al fin y al cabo,
necesitamos que el GP sepa cuándo está tocando los bounds, para poder 
rechazar las partículas. 

Con el modelo fijo fue necesario muestrear principalmente partículas
con overlap >= 0.14, y eso que las más mejores andaban por 0.16.

De hacer el modelo mixto, usaría GPs y no MVN, y no sé si usaría el 
approach de dos pasos (Lunn method) o intentaría muestrear un single
model con todos los GPs a la vez. Ahí sería mejor usar Gibbs y no un
random walk, porque la dimensión es enorme (57 x 6?).



..... IDEAS PARA MEJORAR ....................................................
(pensando en un modelo jerárquico)
2023-10-10

* Ajustar los GP en escala overlap, no log ni logit.

* No restringir el signo de los parámetros.

* Agregar un parámetro al modelo que sea "steps": número máximo posible de 
  ciclos de quema. A la par, permitiría que la probabilidad de propagación
  tenga upper_limit = 1.
  Esto haría que los fuegos no salgan taaan parcheados como salen. Ese parcheo
  puede traer malas consecuencias al simular dinámica de vegetación (imagine
  many patches of unburned forest in the burned area).

* Probar SEQUENTIAL MONTE CARLO. Los GPs son tediosos, llevan mucho tiempo, y 
	llegado un punto, para que funcionen bien, hay que darles muchos datos, 
	lo que hace muy costoso seguir mejorando el overlap. 
	
	O algo parecido al SMC, total solo necesitamos encontrar el pico de la likelihood.

	RESULTADO: esto anduvo muy bien, al menos desde que llegué a un overlap de 0.24
	con los GP, con el smc pude llegar rápidamente a ~0.3.
	Hay una zona compicada en la likelihood que se supera en overlap > 0.2,
	al menos con el fuego ese 2008_3, pero me suena que puede pasar con otros.
	
	PROBAR SI EL SMC funciona bien desde el comienzo! Recordar que acá la parte 
	difícil se pasó usando los GP.
	
* Si llegamos a una likelihood acampanada, probar ajustar un SMVN con el paquete
	sn. Si remuestreamos los datos con overlap > 0.2, usando prob = overlap,
	luego podemos ajustar la distri con sn::selm.fit. Al menos para el incendio 
	2008_3 anduvo muuuy bien.
	
* Chequear si la aproximación de la distrib por remuestreo es fiable. 
	Simular partículas tipo sobol en la box de las buenas partículas. Para cada una
	calcular la densidad en una smvn. Luego remuestrear de acuerdo a esa prob,
	ajustar una smvn con esas remuestras y comparar la distri original
	con la aproximada.
	
	Me suena que no está bien reescalar el overlap antes de remuestrear. reduce
	mucho la incertidumbre. También se puede evaluar ese efecto
	con simulaciones.
	
	
----
Lo más actualizado está en pseudolikelihood_estimation_[...]_03	
	

Lo lindo de estos métodos es que al no tener los GP ni los MVN en stan, 
ajustar muchos fueguitos pequeños sería muy fácil.


* Cuando estemos en la zona 3 de la likelihood, con fuegos que encuentran 
	barreras, podemos detectarlo ajustando un gam al intercept 
	y viendo cómo cambia su derivada. Donde se aplana luego de un pico, 
	o en el punto de inflexión, de ahí para arriba se puede enfocar
	la búsqueda de partículas.
	
* Quizás convenga aprender todo esto primero con fuegos peques, para no 
	andar con ineficiencias en fuegos gigantes que tardan horas en correr 800 partículas.


-----
retomando el 2023-11-23.

Ahora sigo con el SMC en 
pseudolikelihood_estimation_smc_01.R
Este script se hereda de
pseudolikelihood_estimation_gp_waves_03.R 

Probar el simulador con límite de steps, a ver si llegamos a un 
overlap más alto. 

Leer bien lo de arriba que dice "..IDEAS PARA MEJORAR..".
No es correcto usar solamente el overlap para remuestrear y aproximar una distri
porque hay que considerar que esas partículas están ahí por haber salido
de partículas anteriores con cierta probabilidad.

Hay un paper que leí hace poco que explica bien cómo deberían calcularse los 
weights.

De todos modos, si solo busco explorar el espacio para luego ajustar un 
modelo al overlap a partir de esos puntos (sin remuestreo), no hace falta
que recalcule los weights. Simplemente voy explorando las zonas de mayor
overlap de forma bruta.

## estimar la likelihood con una función genérica de kdevine!
## así nos evitamos los problemas con las likelihoods bimodales. 
## son un dolor de cabeza.
## Aunque no vamos a zafar de muestrearlas, ya que luego habrá que hacer el
   MCMC sobre esas likelihoods.


-----
2023-12-02

El ABC funciona por rejection dado un umbral de distancia(obs, sim).
Si directamente muestreamos la similitud, vamos a tener un error de aproximación
mucho más grande. Básicamente, la teoría dice que mientras más astringente el umbral,
menor el error. Entonces, deberíamos aceptar las partículas lo más cercanas posible
al máximo de la similitud. Es como definir una likelihood plana que tiene soporte
en similitud > umbral. 

El problema es que si queremos un modelo mixto, sí o sí necesitaremos que todas
las likelihoods compartan soporte para los parámetros no jerárquicos. Si no lo
comparten, la likelihood conjunta para ese parámetro se hace cero. Y lograr que los
210 datos (incendios) tengan soporte común es casi imposible. 

Entonces necesitamos definir densidades que no tengan soporte compacto, sino que 
desciendan hacia -Inf muy de a poco, para poder evaluarlas. Una forma de lograrlo
sería así:

* Buscar la zona de mayor similitud(obs, sim).
* Ajustar un GP a todos los datos. Aunque solo importe el pico, ajustándolo 
	con menos datos funciona muy mal (crea un pico que no existe). 
* Muestrear esa "likelihood" con un umbral alrededor del percentil 95 % de los 
	fitted values. Pero cuando esta likelihood se anule, no debería devolver cero,
	para no tener soporte compacto. Ahí se devuelve el resultado de una MVN (or skew-).
* Para obtener una MVN, le hacemos un MCMC a ese GP y le ajustamos una distri a
	las muestras. A esa MVN le encogemos bastante la varianza, para que 
	no arroje valores más altos que los debidos. Luego pensar bien cuál es el
	encogimiento óptimo.

# Todo esto está probado al final de
<pseudolikelihood_estimation_gp_fit_mcmc.R>	




____
2023-12-05

Todo anda medio mal, porque la likelihood no parece ser tan identificable. 
Aparentemente, el GP estaba copiando terriblemente la previa. 

Al menos para el fuego 2008_3, hay muchísima corr entre el intercept y los 
betas. Entonces es imposible ajustar una función decente si no usamos un soporte
compacto. 

IDEA: hasta ahora, la previa siempre fue algo informativa, no compacta.
De ahora en más, ajustaremos una likelihood compacta. Es decir, usaremos una
previa uniforme rectangular. Aquí ajustaremos un GAM re complejo, y como 
en todo el soporte habrá datos, no tendremos el problema de que se nos vaya al upite.
A ese gam podríamos ir complejizándolo a medida que juntamos más datos.


probar al final de smc_02. Esto anduvo medio medio.


-------

EUREKAAAAAA

en smc_02, en 
# Búsqueda del máximo con previas planas pero cuadradas -------------------

le tunié la var_factor en 1, y con una previa plana compacta más razonable
encontró una likelihood muy buena. Le ajusté un GAM y va re bien.
Tiene como 5600 datos. Puedo probar cuánto tarda un GP.



--------------

Seguir en 
single fire posterior - surrogate vs simulator.R

donde puse "seguir acá". El gam bernoulli anda bien, pero debería muestrear
más puntos en donde tiene mucha incertidumbre. 

Tirar una nueva seq de sobol muy grande (1e5 o 1e6), cuantificar el width
del IC95 y remuestrear esas partículas en base al IC.

Luego simular en esas partículas.







